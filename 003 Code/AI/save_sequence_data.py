# ì† ì¸ì‹ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ ì½”ë“œ


import cv2
import mediapipe as mp
import csv
import os
import numpy as np # ë„˜íŒŒì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

def collect_hand_landmark_samples(
    label,
    save_path,
    frames_per_sample=30,
    samples_per_video=25
):
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)
    mp_drawing = mp.solutions.drawing_utils

    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    frame_buffer = []
    sample_count = 0
    file_exists = os.path.isfile(save_path)

    with open(save_path, 'a', newline='') as f:
        writer = csv.writer(f)

        # CSV í—¤ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± (í—¤ë” ë‚´ìš©ì€ ë™ì¼)
        if not file_exists:
            header = []
            for i in range(frames_per_sample):
                for j in range(126):
                    header.append(f"f{i}_v{j}")
            header.append("label")
            writer.writerow(header)

        print("â–¶ ë‘ ì† ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì‹œì‘ (30í”„ë ˆì„ x 5ìƒ˜í”Œ)")

        while cap.isOpened() and sample_count < samples_per_video:
            ret, frame = cap.read()
            if not ret:
                break

            frame = cv2.flip(frame, 1)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = hands.process(rgb)

            # --- ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ğŸ‘‡ ---

            # ë‘ ì† ë°ì´í„° ì´ˆê¸°í™”
            hand_data = {"Left": [0.0] * 63, "Right": [0.0] * 63}
            hand_detected = {"Left": False, "Right": False}

            if results.multi_hand_landmarks and results.multi_handedness:
                # 1. ë¨¼ì € ëª¨ë“  ëœë“œë§ˆí¬ì˜ ì ˆëŒ€ ì¢Œí‘œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
                for hand_landmarks, hand_handedness in zip(results.multi_hand_landmarks, results.multi_handedness):
                    hand_label = hand_handedness.classification[0].label  # 'Left' or 'Right'
                    
                    coords = []
                    for lm in hand_landmarks.landmark:
                        coords.extend([lm.x, lm.y, lm.z])
                    
                    hand_data[hand_label] = coords
                    hand_detected[hand_label] = True

                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                
                # 2. ì†ëª© ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.
                normalized_left_coords = [0.0] * 63
                normalized_right_coords = [0.0] * 63

                # ì™¼ì†ì´ ê°ì§€ë˜ì—ˆì„ ê²½ìš°
                if hand_detected["Left"]:
                    left_hand_np = np.array(hand_data["Left"]).reshape(21, 3)
                    left_wrist = left_hand_np[0] # 0ë²ˆ ëœë“œë§ˆí¬ê°€ ì†ëª©
                    relative_left = left_hand_np - left_wrist
                    normalized_left_coords = relative_left.flatten().tolist()

                # ì˜¤ë¥¸ì†ì´ ê°ì§€ë˜ì—ˆì„ ê²½ìš°
                if hand_detected["Right"]:
                    right_hand_np = np.array(hand_data["Right"]).reshape(21, 3)
                    right_wrist = right_hand_np[0] # 0ë²ˆ ëœë“œë§ˆí¬ê°€ ì†ëª©
                    relative_right = right_hand_np - right_wrist
                    normalized_right_coords = relative_right.flatten().tolist()
                
                # 3. ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í•˜ë‚˜ì˜ í”„ë ˆì„ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤.
                one_frame = normalized_left_coords + normalized_right_coords

                # --- ğŸ‘† ì—¬ê¸°ê¹Œì§€ê°€ í•µì‹¬ ë³€ê²½ ë¶€ë¶„ì…ë‹ˆë‹¤ ğŸ‘† ---

                frame_buffer.append(one_frame)

                if len(frame_buffer) == frames_per_sample:
                    sample = [val for frame in frame_buffer for val in frame]
                    sample.append(label)
                    writer.writerow(sample)
                    sample_count += 1
                    frame_buffer = []
                    print(f"âœ” ì €ì¥ë¨: ìƒ˜í”Œ {sample_count}/{samples_per_video}")

                    print("â¸ ë‹¤ìŒ ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ë ¤ë©´ ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”...")
                    while True:
                        cv2.imshow("Dual Hand Sample Collector", frame)
                        if cv2.waitKey(0) != -1:
                            break
            else:
                frame_buffer = []

            cv2.imshow("Dual Hand Sample Collector", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("ğŸ›‘ ìˆ˜ì§‘ ì¤‘ë‹¨ë¨")
                break

    cap.release()
    cv2.destroyAllWindows()
    print(f"âœ… ì „ì²´ {sample_count}ê°œ ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ â†’ {save_path}")


if __name__ == "__main__":
    label = "ìš´ë™ì¥"  # í…ŒìŠ¤íŠ¸í•  ë¼ë²¨
    collect_hand_landmark_samples(
        label=f"{label}",
        save_path=f"data/{label}_sequences.csv"

    )
